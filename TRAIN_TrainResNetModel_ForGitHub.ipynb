{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1b6bab2-29c3-4038-b699-b76ffcaeb310",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tifffile\n",
    "import cv2\n",
    "from os.path import join, isfile, exists\n",
    "import torch\n",
    "from torchview import draw_graph\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torchcam.utils import overlay_mask\n",
    "from torchcam.methods import SmoothGradCAMpp\n",
    "from torchcam.methods import CAM\n",
    "import os\n",
    "from PIL import Image\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import copy\n",
    "import warnings\n",
    "import contextlib\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f371a487-e2c7-4e93-ab35-33228be9c3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagePath = 'C:/Users/aruys/Dropbox (GaTech)/CZIConverted'\n",
    "\n",
    "def strTmpt(t):\n",
    "    if t == 1:\n",
    "        return 't001'\n",
    "    elif t < 100:\n",
    "        return 't0'+str(t)\n",
    "    else:\n",
    "        return 't'+str(t)\n",
    "\n",
    "#returns the treatment condition for a particular sample\n",
    "#-samp is the sample name\n",
    "#-condFile is a .csv file with the sample names and conditions\n",
    "# each stored in separate columns\n",
    "#-condName is the name of the column of conditions in the file\n",
    "#-sampName is the name of the column of sample names in the file\n",
    "def get_condition(samp,condFile,condName = 'conds',sampName = 'samps'):\n",
    "    df = pd.read_csv(condFile)\n",
    "    return df[condName][list(df[sampName]).index(samp)]\n",
    "\n",
    "#creates a dataset of labeled sample images for a particular neural network, all\n",
    "#from a single timepoint.\n",
    "#The initialization assumes the images are stored in folders according to \n",
    "#sample, and then labeled by timepoint\n",
    "#-root_dir, the directory of the image folder\n",
    "#-condFile, the .csv file listing the treatment conditions for each sample\n",
    "#-timestamp: the timepoint for which we are taking the sample images\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, root_dir, condFile, transform=None, timestamp=1):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        label_map \n",
    "        for folder in os.listdir(root_dir):\n",
    "            if len(folder) == 5 and (folder[:2] == '22' or folder[:2] == '26'):\n",
    "                folder_path = os.path.join(root_dir, folder)\n",
    "                files = [f for f in os.listdir(folder_path) if isfile(join(folder_path, f))]\n",
    "                label = get_condition(folder,condFile)\n",
    "                for file in files:\n",
    "                    file_path = os.path.join(folder_path, file)\n",
    "                    #in our case we had to distinguish between channel 1 'c001' and channel 2 'c002' of the image\n",
    "                    match = re.search(r'_t(\\d+)_c002', file)\n",
    "                    if match:\n",
    "                        number = int(match.group(1))\n",
    "                        if number == timestamp:\n",
    "                            if file_path.endswith(\".png\"):\n",
    "                                img = Image.open(file_path).convert(\"RGB\")\n",
    "                                name = file.split(\"_\")[0]\n",
    "                                label = label_map.get(label, -1)\n",
    "                                if label != -1:\n",
    "                                    self.images.append(img)\n",
    "                                    self.labels.append(label)\n",
    "                            elif file_path.endswith(\".tif\"):                     \n",
    "                                try:\n",
    "                                    image_array = tifffile.imread(file_path)\n",
    "                                except TypeError:\n",
    "                                    pass\n",
    "                                img_rescaled = 255 * (image_array - image_array.min()) / (image_array.max() - image_array.min())\n",
    "                                img_col = cv2.applyColorMap(img_rescaled.astype(np.uint8), cv2.COLORMAP_DEEPGREEN)\n",
    "                                img = Image.fromarray(img_col)\n",
    "                                img = img.convert(\"RGB\")\n",
    "                                name = file.split(\"_\")[0]\n",
    "                                label = label_map.get(label, -1)\n",
    "                                if label != -1:\n",
    "                                    self.images.append(img)\n",
    "                                    self.labels.append(label)\n",
    "                                break\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        # apply transformation         \n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img, label\n",
    "\n",
    "def train_model(model, criterion, optimizer, dataloaders, num_epochs=100, debug=False):\n",
    "    since = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    loss_values = []\n",
    "    for epoch in range(num_epochs+1):\n",
    "        if epoch % 5 == 0 and debug:\n",
    "            print(f'Epoch {epoch}/{num_epochs}')\n",
    "            \n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "                \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            total = 0\n",
    "            \n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs.data, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        \n",
    "                running_loss += loss.item()\n",
    "                running_corrects += (preds == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase])\n",
    "            loss_values.append(epoch_loss)\n",
    "            epoch_acc =  running_corrects / total\n",
    "            if epoch % 5 == 0 and debug:\n",
    "                print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')   \n",
    "                \n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        if epoch % 5 == 0 and debug:  \n",
    "            print('-' * 10)\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Acc: {best_acc:4f}')\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, loss_values\n",
    "\n",
    "def get_metrics(model, test_dataloader):\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "    accuracy_values = []\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_dataloader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "            predicted_labels.extend(predicted.cpu().numpy())\n",
    "\n",
    "    precision = precision_score(true_labels, predicted_labels, average='macro')\n",
    "    recall = recall_score(true_labels, predicted_labels, average='macro')\n",
    "    f1 = f1_score(true_labels, predicted_labels, average='macro')\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "#-imRroot is the directory of the image folders\n",
    "#-time is the timepoint at which we are training/testing\n",
    "#-condFile is the .csv file which has the treatment condition for each sample\n",
    "#-train is whether we are training a model, or just testing an already existing one\n",
    "\n",
    "def get_dataloaders(imRoot, time, condFile, train = True):\n",
    "    dataset = ImageDataset(imRoot, condFile, transform=transform, timestamp=time)\n",
    "    \n",
    "    if train:\n",
    "        train_dataset, test_dataset = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "        train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "        test_dataloader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "        dataloaders = {'train': train_dataloader, 'val': test_dataloader}\n",
    "        return dataloaders\n",
    "    else:\n",
    "        test_dataloader = DataLoader(dataset, batch_size=8,shuffle = False)\n",
    "        return test_dataloader\n",
    "\n",
    "label_map = {\"BMP4\" :0, \"CHIR\": 1, \"DS\": 2, \"DS+CHIR\": 3,  \"WT\": 4}\n",
    "input_shape = (3, 224, 224)\n",
    "num_classes = 5\n",
    "\n",
    "# Define the data transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(input_shape[1:]),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "104748f6-25d1-4d35-82d7-396852fd7e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-imRroot is the directory of the image folders\n",
    "#-time is the timepoint at which we are training/testing\n",
    "#-condFileTr is the .csv file which has the treatment condition for each sample (for training)\n",
    "#-condFileTe is the .csv file which has the treatment condition for each sample (for testing)\n",
    "#    the different condition file names are for cases like say, you want to train the model\n",
    "#    on randomized labels and test on the actual labels, as a control\n",
    "#-train is whether we are training a model, or just testing an already existing one\n",
    "#-saveModel is whether to save the model\n",
    "#-modelName is the filename of the model if saved\n",
    "def train_at_Tmpt(t,condFileTr,condFileTe,saveModel = 1, modelName = 'MyResNetModel.pt'):\n",
    "    tOI = strTmpt(t)\n",
    "    model = models.resnet18(pretrained=True)\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    model.fc = nn.Identity()\n",
    "    model.fc.requires_grad = True\n",
    "    model.fc = nn.Linear(512, num_classes)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.fc.parameters(), lr=0.001, momentum=0.9)\n",
    "    model = model.to(device)\n",
    "    original_stderr = sys.stderr\n",
    "    sys.stderr = open(os.devnull, 'w')\n",
    "\n",
    "    dataloaders = get_dataloaders(imRoot,t,condFileTr)\n",
    "    model_trained, loss_values = train_model(model, criterion, optimizer, dataloaders, num_epochs=50)\n",
    "    dataloaders_actuallabel = get_dataloaders(imRoot,t,condFileTe)\n",
    "    accuracy, precision, recall, fOne = get_metrics(model_trained, dataloaders_actuallabel['val'])\n",
    "    if saveModel==1:\n",
    "        torch.save(model_trained, modelName)\n",
    "    sys.stderr = original_stderr\n",
    "    timestamp:  1\n",
    "    return accuracy, precision, recall, fOne, model_trained"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
